# Google Colab link: https://colab.research.google.com/drive/1XlztOJ8al-Je2ARXjf8_z74g6ugAtO1Q#scrollTo=ztuk3JoidjmR

from google.colab import drive
from pathlib import Path
import os

#Load Google drive
drive.mount('/content/drive')

#Connect the data 
DATA_DIR = Path("/content/drive/MyDrive/pums_project_data")
DATA_DIR.mkdir(parents=True, exist_ok=True)

print("Working dir:", os.getcwd())
print("Saving data to:", DATA_DIR.resolve())

# STEP 1: Data import 
import pandas as pd
import numpy as np

# Upload CSV file #previously API connection but that broke
PUMS_FILE = "/content/drive/MyDrive/CUNY GRAD/Data7200_Advanced Analytics/ACS Data/psam_pusb.csv"

# Starting variables, may upload region later
USECOLS = [
    "AGEP",   # Age (numeric)
    "SEX",    # Sex (categorical code)
    "SCHL",   # Educational attainment (ordinal code)
    "ESR",    # Employment status (1,2 = employed civilians)
    "COW",    # Class of worker (2 = private not-for-profit)
    "DIS",    # Disability (categorical) - TBD IF USED FOR PROJECT 
]

# Read file 
available_cols = pd.read_csv(PUMS_FILE, nrows=0).columns.tolist()
keep = [c for c in USECOLS if c in available_cols]
raw_df = pd.read_csv(PUMS_FILE, usecols=keep)

print("Loaded shape:", raw_df.shape)
raw_df.head()

# Keep adults (18+) & employed civilians (ESR 1 or 2) in NGOs
if "AGEP" in raw_df.columns and "ESR" in raw_df.columns:
    raw_df = raw_df[(raw_df["AGEP"] >= 18) & (raw_df["ESR"].isin([1, 2]))].copy()

print("After 18+ & employed filter:", raw_df.shape)

# Check for variable is missing
for needed in ["AGEP","SEX","SCHL","ESR","COW","DIS"]:
    if needed not in raw_df.columns:
        print(f"NOTE: Column '{needed}' not found; it will be dropped if referenced later.")

# STEP 2: Train/test
from sklearn.model_selection import train_test_split

# Label: nonprofit worker (COW = 2), If person works for NGO convert to 1(True), othewise (0)
raw_df["nonprofit_worker"] = (raw_df.get("COW", pd.Series([np.nan]*len(raw_df))) == 2).astype(int)

# Choosing varibles for reature columns
candidate_features = ["AGEP","SEX","SCHL","DIS"]  # use of REGION TBD, adding DIS for now
feature_cols = [c for c in candidate_features if c in raw_df.columns]
target_col = "nonprofit_worker"

# Drop rows with missing data (NAN)
df = raw_df.dropna(subset=[target_col]).copy()

# Split features (Age, Sex, Ed, Dis) & target (NGO)
X = df[feature_cols].copy()
y = df[target_col].copy()

# Train/Test 25% data, split by 42
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.25, random_state=42, stratify=y
)

print("Train size:", X_train.shape, " Test size:", X_test.shape)
print("Train class balance:\n", y_train.value_counts(normalize=True))
print("Test class balance:\n", y_test.value_counts(normalize=True))

# STEP 3: combine feature and target
train_df = X_train.copy()
train_df[target_col] = y_train.values

print("DataFrame.info():")

# Set the structure
train_df.info()

print("\nDataFrame.describe():")

# Summary stats
train_df.describe(include="all")

# STEP 4: Impute (fill) missing values; save cleaned train/test to Drive
from sklearn.impute import SimpleImputer

# With the kept variables: SCHL (ordinal) + AGEP are numeric; SEX/DIS/REGION are categorical-coded
numeric_cols = [c for c in ["AGEP","SCHL"] if c in X_train.columns]
categorical_cols = [c for c in ["SEX","DIS","REGION"] if c in X_train.columns]

# num imputer fill numeric values missing & cat imputer fill missing cat values
num_imputer = SimpleImputer(strategy="median")
cat_imputer = SimpleImputer(strategy="most_frequent")

# fit into training data
X_train_num = pd.DataFrame(num_imputer.fit_transform(X_train[numeric_cols]),
                           columns=numeric_cols, index=X_train.index) if numeric_cols else pd.DataFrame(index=X_train.index)
X_train_cat = pd.DataFrame(cat_imputer.fit_transform(X_train[categorical_cols]),
                           columns=categorical_cols, index=X_train.index) if categorical_cols else pd.DataFrame(index=X_train.index)
X_train_clean = pd.concat([X_train_num, X_train_cat], axis=1)

# fit imputers into test data
X_test_num = pd.DataFrame(num_imputer.transform(X_test[numeric_cols]),
                          columns=numeric_cols, index=X_test.index) if numeric_cols else pd.DataFrame(index=X_test.index)
X_test_cat = pd.DataFrame(cat_imputer.transform(X_test[categorical_cols]),
                          columns=categorical_cols, index=X_test.index) if categorical_cols else pd.DataFrame(index=X_test.index)
X_test_clean = pd.concat([X_test_num, X_test_cat], axis=1)

# NGO target to train/test
train_clean_df = X_train_clean.copy()
train_clean_df[target_col] = y_train.values
test_clean_df  = X_test_clean.copy()
test_clean_df[target_col]  = y_test.values

# Save the data to avoid reruning processing
train_out = DATA_DIR / "pums_train_clean.csv"
test_out  = DATA_DIR / "pums_test_clean.csv"
train_clean_df.to_csv(train_out, index=False)
test_clean_df.to_csv(test_out, index=False)

# Confirm data is saved
print("Saved to Drive:")
print(" -", train_out)
print(" -", test_out)


# STEP 5: Visualizations with available columns
import matplotlib.pyplot as plt
from pandas.plotting import scatter_matrix

# create lables
df["SEX_label"] = df["SEX"].map({1: "Male", 2: "Female"})
df["DIS_label"] = df["DIS"].map({1: "With Disability", 2: "No Disability"})

# plot histograms
_ = train_clean_df.hist(figsize=(12, 10), bins=30)
plt.tight_layout()
plt.show()

# Use numeric columns for scatter matrix (AGEP, SCHL)
sm_cols = [c for c in ["AGEP","SCHL"] if c in train_clean_df.columns]

# Plot scatter matrix if at least two numeric columns exits 
if len(sm_cols) >= 2:
    _ = scatter_matrix(train_clean_df[sm_cols], figsize=(10, 10), diagonal="hist")
    plt.tight_layout()
    plt.show()
else:
    print("Not enough numeric columns for scatter_matrix; skipping.")

# STEP 6: Transform AGEP and SCHL 

import numpy as np #had to reload 

# run logarithm func
def safe_log(x):
    return np.log1p(np.clip(x, a_min=0, a_max=None))

# run exponential func
def safe_exp(x):
    # avoid overflow in demo
    return np.exp(np.clip(x, a_min=None, a_max=12))

# bakcup copy to keep original unaltered
transformed = train_clean_df.copy()

# Transform by ietrating AGEP and SCHL
numeric_for_tx = []
for col in ["AGEP", "SCHL"]:
    if col in transformed.columns:
        transformed[f"{col}_sq"]  = transformed[col] ** 2
        transformed[f"{col}_cu"]  = transformed[col] ** 3
        transformed[f"{col}_log"] = safe_log(transformed[col])
        std = transformed[col].std() if transformed[col].std() else 1.0
        transformed[f"{col}_exp"] = safe_exp(transformed[col] / std)
        numeric_for_tx.extend([col, f"{col}_sq", f"{col}_cu", f"{col}_log", f"{col}_exp"])

# plot histogram for aviable variables
if numeric_for_tx:
    _ = transformed[numeric_for_tx].hist(figsize=(14, 10), bins=30)
    import matplotlib.pyplot as plt
    plt.tight_layout()
    plt.show()

# plot scatter for the variables 
    from pandas.plotting import scatter_matrix
    sm_show = [c for c in ["AGEP","AGEP_log","SCHL","SCHL_log"] if c in transformed.columns]
    if len(sm_show) >= 2:
        _ = scatter_matrix(transformed[sm_show], figsize=(10, 10), diagonal="hist")
        plt.tight_layout()
        plt.show()
else:
    print("AGEP/SCHL not available; skipping transformations.")


